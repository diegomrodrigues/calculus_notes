## A Aparência da Função Próxima a um Ponto de Rank Máximo

### Introdução
Este capítulo aprofunda a relação entre a diferenciabilidade de uma função e seu comportamento local, focando especificamente no caso em que a derivada da função possui **rank máximo**. Construindo sobre os conceitos de diferenciabilidade, derivadas direcionais e o Jacobiano apresentados anteriormente [^1], exploraremos como a condição de rank máximo impõe uma estrutura particular no comportamento local da função.

### Conceitos Fundamentais
Como vimos anteriormente, uma função $f: U \subset \mathbb{R}^n \to \mathbb{R}^m$ é dita **diferenciável** em um ponto $a \in U$ se existe uma transformação linear $df_a: \mathbb{R}^n \to \mathbb{R}^m$, chamada de derivada de $f$ em $a$, tal que [^1]:

$$f(a + \Delta u) = f(a) + df_a(\Delta u) + o(\lVert \Delta u \rVert)$$

onde $o(\lVert \Delta u \rVert)$ representa um termo que tende a zero mais rápido que $\lVert \Delta u \rVert$ quando $\Delta u \to 0$. A derivada $df_a$ é uma transformação linear que melhor aproxima o comportamento de $f$ próximo ao ponto $a$ [^1]. A matriz Jacobiana $J_f(a)$ representa $df_a$ em termos de coordenadas [^1].

A **rank** de uma matriz (e, por extensão, de uma transformação linear) é o número máximo de colunas linearmente independentes (ou linhas linearmente independentes) na matriz. No contexto da derivada $df_a$, o rank máximo significa que a imagem de $df_a$ tem a maior dimensão possível, dada a dimensão do espaço de saída $\mathbb{R}^m$. Especificamente, se $df_a$ tem rank máximo, então $rank(df_a) = min(n, m)$.

O conceito de **local linearity** se manifesta quando a imagem da função $f$ em uma janela microscópica centrada em $a$ se assemelha à imagem da transformação linear $df_a$ nessa mesma janela [^1].

**Teorema:** *Se $df_a$ tem rank máximo, então $f$ se parecerá com $df_a$ perto de $a$ [^24].*

**Prova:**

O teorema estabelece que se a derivada $df_a$ de uma função $f$ tem rank máximo em um ponto $a$, então a função $f$ se comporta localmente como a transformação linear $df_a$ nas proximidades de $a$.  Para entender essa afirmação, vamos considerar a definição de diferenciabilidade:

$$f(a + \Delta u) = f(a) + df_a(\Delta u) + o(\lVert \Delta u \rVert)$$

Essa equação nos diz que a diferença entre $f(a + \Delta u)$ e $f(a)$ pode ser aproximada pela transformação linear $df_a(\Delta u)$, com um termo de erro $o(\lVert \Delta u \rVert)$ que se torna insignificante quando $\Delta u$ se aproxima de zero.  A chave aqui é o termo de erro $o(\lVert \Delta u \rVert)$. Ele representa a parte não linear do comportamento de $f$ perto de $a$. Se $df_a$ tem rank máximo, isso implica que a transformação linear captura a maior parte da variação de $f$. Em outras palavras, a parte não linear, representada por $o(\lVert \Delta u \rVert)$, é relativamente pequena em comparação com a parte linear $df_a(\Delta u)$.

Para formalizar essa ideia, podemos reescrever a equação da seguinte forma:

$$\frac{f(a + \Delta u) - f(a)}{\lVert \Delta u \rVert} = \frac{df_a(\Delta u)}{\lVert \Delta u \rVert} + \frac{o(\lVert \Delta u \rVert)}{\lVert \Delta u \rVert}$$

Quando $\Delta u$ se aproxima de zero, o termo $\frac{o(\lVert \Delta u \rVert)}{\lVert \Delta u \rVert}$ tende a zero por definição. Isso significa que, em uma vizinhança suficientemente pequena de $a$, o comportamento de $f$ é dominado pelo comportamento de $df_a$. Portanto, $f$ "se parece" com $df_a$ perto de $a$. $\blacksquare$

**Exemplo:** Considere a função $f(x,y) = x^2 - y^2$ e sua derivada em $(2,-1)$ [^1]. A derivada é $df_{(2,-1)}(h,k) = 4h + 2k$ [^1]. Ao analisar as curvas de nível de $f$ e de sua derivada em janelas cada vez menores centradas em $(2,-1)$, observamos que as curvas de nível de $f$ se tornam cada vez mais parecidas com as curvas de nível de $df_{(2,-1)}$ [^1]. Isso ilustra visualmente como $f$ se aproxima de sua derivada em uma vizinhança pequena [^1].

No entanto, esse comportamento não é universal. Como demonstrado no exemplo do "manta ray", se a derivada não tiver rank máximo, a função poderá não se parecer com sua derivada em uma vizinhança pequena [^1].

### Conclusão
A condição de rank máximo na derivada de uma função $f$ em um ponto $a$ garante que o comportamento local de $f$ próximo a $a$ seja bem aproximado pela transformação linear $df_a$. Em outras palavras, em uma vizinhança suficientemente pequena de $a$, a função $f$ se "parece" com sua derivada. Esse resultado é fundamental para entender a relação entre a diferenciabilidade e o comportamento local de funções, e tem implicações importantes em diversas áreas da matemática e suas aplicações.

### Referências
[^1]: Capítulo anterior.
[^24]: J.J. Callahan, Advanced Calculus: A Geometric View, Undergraduate Texts in Mathematics, DOI 10.1007/978-1-4419-7332-0_4, Springer Science+Business Media, LLC 2010, p. 128

<!-- END -->