## Rank-Two Covariant Tensors: Multilinear Maps and Two-Forms

### Introdução
Este capítulo explora em detalhes os **tensores de rank dois**, focando primariamente nos tensores covariantes (0,2). Como veremos, esses tensores são mapeamentos multilineares que aceitam dois vetores como entrada e retornam um escalar [^403]. Particularmente, as *two-forms* representam um subconjunto específico desses tensores [^403]. Antes de nos aprofundarmos nos detalhes dos tensores de rank dois, é importante estabelecer uma base sólida nos conceitos de produtos cartesianos e multilinearidade.

### Conceitos Fundamentais
#### Produtos Cartesianos de Espaços Vetoriais
O **produto cartesiano** de dois espaços vetoriais $V$ e $W$, denotado por $V \times W$, é definido como o conjunto de todos os pares ordenados $(v, w)$, onde $v \in V$ e $w \in W$ [^404]. Formalmente,
$$V \times W = \{(v, w) \mid v \in V \text{ e } w \in W\}.$$
Se $(v_1, ..., v_n)$ é uma base de $V$ e $(w_1, ..., w_m)$ é uma base de $W$, então $V \times W$ pode ser expresso como:
$$V \times W = \text{span}\{(v_i, 0), (0, w_j) \mid 1 \leq i \leq n, 1 \leq j \leq m\}.$$
Este conceito é fundamental para a construção de tensores, pois fornece a estrutura básica sobre a qual os mapeamentos multilineares são definidos [^404].

#### Tensores (0,2) e Multilinearidade
Um **tensor (0,2)**, também conhecido como tensor covariante de rank dois, é um mapeamento multilinear $T$ que recebe dois vetores como entrada, ambos pertencentes ao espaço tangente $T_pM$, e retorna um escalar [^404]. Formalmente,
$$T: T_pM \times T_pM \rightarrow \mathbb{R}.$$
A **multilinearidade** de $T$ significa que $T$ é linear em cada "slot". Isso implica que para vetores $v_1, v_2, w \in T_pM$ e escalares $a, b \in \mathbb{R}$, as seguintes propriedades são válidas [^404]:
1.  $T(av_1 + bv_2, w) = aT(v_1, w) + bT(v_2, w)$,
2.  $T(v, aw_1 + bw_2) = aT(v, w_1) + bT(v, w_2)$.

#### Two-Forms como Subconjunto de Tensores (0,2)
É crucial notar que nem todo tensor (0,2) é uma *two-form*. *Two-forms* são um subconjunto específico de tensores (0,2) que possuem uma propriedade adicional: são **skew-symmetric** ou **anti-symmetric** [^405]. Isso significa que para uma *two-form* $\omega$, a seguinte relação se mantém:
$$\omega(v, w) = -\omega(w, v).$$
Em contraste, um tensor (0,2) geral $T$ não precisa satisfazer essa propriedade. Não há razão para esperar que $T(v, w)$ esteja relacionado a $T(w, v)$ por uma simples mudança de sinal [^405].

#### Representação em Coordenadas
Em um espaço vetorial bidimensional, um tensor (0,2) $T$ pode ser expresso em termos de seus componentes e da base do espaço tangente [^405]. Se $(dx^1, dx^2)$ é uma base para $T^*M$, então $T$ pode ser escrito como:
$$T = T_{11} dx^1 \otimes dx^1 + T_{12} dx^1 \otimes dx^2 + T_{21} dx^2 \otimes dx^1 + T_{22} dx^2 \otimes dx^2.$$
Usando a notação de Einstein, podemos generalizar isso para:
$$T = T_{ij} dx^i \otimes dx^j.$$
#### Transformação de Tensores Covariantes de Rank 2
Considerando uma mudança de base dada pelas funções $u^i(x_1, ..., x_n)$, a transformação dos componentes de um tensor covariante de rank 2 é dada por [^405]:
$$T_{kl} = \frac{\partial x^i}{\partial u^k} \frac{\partial x^j}{\partial u^l} T_{ij}.$$
Cada índice transforma-se covariantemente.

### Conclusão
Este capítulo estabeleceu as bases para entender tensores covariantes de rank dois, destacando sua natureza como mapeamentos multilineares, sua relação com *two-forms*, e suas propriedades de transformação. A compreensão desses conceitos é crucial para a análise de espaços vetoriais e suas aplicações em diversas áreas da física e da matemática.

### Referências
[^403]: A Introduction to Tensors, p. 403
[^404]: A Introduction to Tensors, p. 404
[^405]: A Introduction to Tensors, p. 405
<!-- END -->